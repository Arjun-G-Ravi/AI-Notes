{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "batch_size = 24\n",
    "lr = .000001\n",
    "pathCircle   = '/home/arjun/Documents/DatasetCollection/shapes/circles'\n",
    "pathTriangle = '/home/arjun/Documents/DatasetCollection/shapes/triangles'\n",
    "pathSquare   = '/home/arjun/Documents/DatasetCollection/shapes/squares'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['circle', 'square', 'triangle']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cir = [ 0. for i in range(100)]\n",
    "tri = [ 2. for i in range(100)]\n",
    "sq =  [ 1. for i in range(100)]\n",
    "all = cir + tri + sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/arjun/Documents/DatasetCollection/shapes/circles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/arjun/Desktop/GitHub/AI-Notes/03_Learning Pytorch/16_CNN: Shape classifier.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arjun/Desktop/GitHub/AI-Notes/03_Learning%20Pytorch/16_CNN%3A%20Shape%20classifier.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m circle_data \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(pathCircle, f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(pathCircle) \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arjun/Desktop/GitHub/AI-Notes/03_Learning%20Pytorch/16_CNN%3A%20Shape%20classifier.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m triangle_data \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(pathTriangle, f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(pathTriangle) \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arjun/Desktop/GitHub/AI-Notes/03_Learning%20Pytorch/16_CNN%3A%20Shape%20classifier.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m square_data \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(pathSquare, f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(pathSquare) \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/arjun/Documents/DatasetCollection/shapes/circles'"
     ]
    }
   ],
   "source": [
    "circle_data = [os.path.join(pathCircle, f) for f in os.listdir(pathCircle) if f.endswith('.png')]\n",
    "triangle_data = [os.path.join(pathTriangle, f) for f in os.listdir(pathTriangle) if f.endswith('.png')]\n",
    "square_data = [os.path.join(pathSquare, f) for f in os.listdir(pathSquare) if f.endswith('.png')]\n",
    "\n",
    "dfCir = pd.DataFrame({'Images':circle_data, 'Shape' : cir})\n",
    "dfTri = pd.DataFrame({'Images':triangle_data, 'Shape' : tri})\n",
    "dfSq = pd.DataFrame({'Images':square_data, 'Shape' : sq})\n",
    "\n",
    "df = dfCir.append(dfTri, ignore_index=True)\n",
    "df = df.append(dfSq, ignore_index=True)\n",
    "df                                # Thus we have the complete dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Images'], df['Shape'], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating custom DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform = None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.df.iloc[index, 0]\n",
    "        label = self.df.iloc[index, 1]\n",
    "\n",
    "        with Image.open(image_path) as img:\n",
    "            image = np.array(img, dtype=np.uint8)\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = torch.from_numpy(image.transpose((2, 0, 1)))\n",
    "        image = image.reshape(-1, 3, 28, 28)\n",
    "\n",
    "        sample = tuple([image,torch.tensor(label)])\n",
    "        # if self.transform:\n",
    "        #     sample = self.transform(sample)\n",
    "        return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(pd.concat([X_train, y_train], axis=1),)#  , transform=transform)\n",
    "test_dataset  = CustomDataset(pd.concat([X_test, y_test], axis=1)  )# , transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(192,120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(64, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x -> (n, 3, 28, 28)\n",
    "        # print(type(x))\n",
    "        # print(x)\n",
    "        # print(x.shape)\n",
    "        out = self.pool(F.relu(self.conv1(x)))    # -> (6, 12, 12)\n",
    "        out = self.pool(F.relu(self.conv2(out)))  # -> (12, 4, 4)\n",
    "        out = out.view(-1, 12*4*4)                # -> (1, 192)\n",
    "        out = F.relu(self.fc1(out))               # -> (1, 120)\n",
    "        out = F.relu(self.fc2(out))               # -> (1, 64)\n",
    "        out = self.fc3(out)                       # -> (1, 3)\n",
    "        return out\n",
    "    \n",
    "model = CNN().to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossCat = nn.CrossEntropyLoss().to(device)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1} / {num_epochs} \")\n",
    "\n",
    "    for image, label in  train_loader:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        # print(image.shape)\n",
    "        image = image.reshape(-1,3,28,28)\n",
    "        y_hat = model(image)\n",
    "        label = torch.tensor(label, requires_grad=True)\n",
    "        y_hat = torch.tensor(torch.argmax(y_hat, dim=1), dtype=torch.float64)\n",
    "        # print(y_hat)\n",
    "        loss = lossCat(label, y_hat)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # print(label)\n",
    "    print(f\" [LOSS = {loss:.3f}]\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
