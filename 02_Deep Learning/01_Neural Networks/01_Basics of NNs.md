# Neural Network Terminologies

## Feedforward NN
A NN where the data traverses in only one direction during inference

## Fully Connected Layer
A layer where each neuron is connected with every other neuron in the previous layer.

## Activation Function
The activation function is a mathematical operation that is applied to the output of a neuron before it is passed on to the next neuron. The activation function determines how the neuron will respond to its inputs. It activates a neuron, based on a threshold. Some activation functions are:
 - Sigmoid function: f(z) = 1/(1+e-z)
 - Linear function : f(z) = z. (or ‘no function’).
 - ReLu (Rectified linear activation function): f(z) = max(0,z). It is preferred in hidden layers.
 - tanh: Another popular activation function for hidden layers.

