# NLP Pipeline

## 1. Data Acquisition
- Collect data from various sources
- If not directly available, you can web scrape or do surveys
- Nowadays, you can even use LLMs to create data

## 2. Text cleaning
- Using regex to extract only necessary sections
- Correcting spelling mistakes

## 3. Text preprocessing
- Tokenisation
- Lower casing
- Stemming/ Lemmatisation
- POS tagging
- Text normalisation
- Named Entity recognition
- Relationship extraction
- Coreference resolution

## 4. Feature Enginnering
- Extracting meaningful information from raw data
- Better data -> Better model

## 5. Model Building
NLP models comes in three types:
1. Heuristic model 
   - Rule based
   - good with small data
2. ML based models
   - With a moderately large dataset
3. Deep learning based model
   - With huge datasets
   - Use RNNs, LSTMs, Transformers   

Ensemble and stacking of models can almost always lead to better performing models

## 6. Evaluation
- Can be intristic or extensic
## 7. Deployment
- Cloud services can be used
## 8. Monitoring and updating
- Update model with recent data
- Remove model's mistakes and biases