{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/AI_ENV/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()  # Is GPU available"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising and Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([1,2,3])\n",
    "print(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/arjun/Desktop/GitHub/AI-Notes/03_Pytorch/01_PytorchBasics.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arjun/Desktop/GitHub/AI-Notes/03_Pytorch/01_PytorchBasics.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Only with GPU\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arjun/Desktop/GitHub/AI-Notes/03_Pytorch/01_PytorchBasics.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arjun/Desktop/GitHub/AI-Notes/03_Pytorch/01_PytorchBasics.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(t)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arjun/Desktop/GitHub/AI-Notes/03_Pytorch/01_PytorchBasics.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Choose GPU, if available\u001b[39;00m\n",
      "File \u001b[0;32m~/AI_ENV/lib/python3.10/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    299\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "# Only with GPU\n",
    "t = t.to('cuda')\n",
    "print(t)\n",
    "\n",
    "# Choose GPU, if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy array vs Pytorch tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to share memory and avoid copying data whenever possible,\n",
    "use torch.from_numpy. If you want more control over memory sharing or \n",
    "prefer to create a new tensor, use torch.as_tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4]) tensor([1, 2, 3, 4])\n",
      "[1 2 3 4] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "data = np.array([1,2,3,4])\n",
    "t1 = torch.as_tensor(data)\n",
    "t2 = torch.from_numpy(data)\n",
    "print(t1,t2)\n",
    "\n",
    "t1 = t1.numpy()\n",
    "print(t1, type(t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identity, Zero, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[[0.1112, 0.2192, 0.4569],\n",
      "         [0.4744, 0.8282, 0.6311]]])\n",
      "tensor([[[-0.7918,  0.5660,  1.2893],\n",
      "         [ 1.4038,  0.8896,  0.1650]]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.eye(5)\n",
    "print(t)\n",
    "t = torch.ones([3,4])\n",
    "print(t)\n",
    "t = torch.rand([1,2,3])  # Range [0,1)\n",
    "print(t)\n",
    "t = torch.randn([1,2,3])  # These numbers have a  mean of 0 and a std deviation of 1.\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5, 6], dtype=torch.int8)\n",
      "tensor(5, dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "RANK = 2 (Number of axes[or dimensions]) and (2 indexes are needed to denote an element)\n",
    "LENGTH OF AXES = 3\n",
    "SHAPE OF TENSOR = 3 X 3  # Length of shape = rank\n",
    "'''\n",
    "t = torch.tensor([[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9]], dtype=torch.int8)\n",
    "print(t[1])\n",
    "print(t[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([[10, 20, 30],\n",
      "        [40, 50, 60],\n",
      "        [70, 80, 90]])\n",
      "tensor([[11, 22, 33],\n",
      "        [44, 55, 66],\n",
      "        [77, 88, 99]])\n",
      "tensor([[33, 34, 35],\n",
      "        [36, 37, 38],\n",
      "        [39, 40, 41]])\n",
      "tensor([[ -9, -18, -27],\n",
      "        [-36, -45, -54],\n",
      "        [-63, -72, -81]])\n",
      "tensor([[ 10,  40,  90],\n",
      "        [160, 250, 360],\n",
      "        [490, 640, 810]])\n",
      "tensor([[ 300,  360,  420],\n",
      "        [ 660,  810,  960],\n",
      "        [1020, 1260, 1500]])\n",
      "tensor([[0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000]])\n",
      "tensor(5.)\n",
      "27.386127471923828\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.as_tensor(np.array([[1,2,3],\n",
    "                              [4,5,6],\n",
    "                              [7,8,9]]))\n",
    "t2 = torch.as_tensor(np.array([10,20,30,40,50,60,70,80,90])).reshape(3,3)  # Reshape\n",
    "print(t1)\n",
    "print(t2)  \n",
    "\n",
    "print(t1+t2)  # Add\n",
    "print(t1+32)  # Element wise Addition (BROADCASTING)\n",
    "print(t1-t2)  # Sub\n",
    "print(t1*t2)  # Element wise multiplication\n",
    "print(t1@t2)  # MatMul\n",
    "print(t1/t2)  # Element wise division\n",
    "print(t1.float().mean())  # Conversion, Mean\n",
    "print(t2.float().std().item())  # Conversion, Std deviation, item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-place operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 22, 33],\n",
      "        [44, 55, 66],\n",
      "        [77, 88, 99]])\n",
      "tensor([[11, 22, 33],\n",
      "        [44, 55, 66],\n",
      "        [77, 88, 99]])\n",
      "tensor([[10, 20, 30],\n",
      "        [40, 50, 60],\n",
      "        [70, 80, 90]])\n"
     ]
    }
   ],
   "source": [
    "print(t1.add_(t2))  # _ indicates that it is an in-place funciton \n",
    "print(t1)\n",
    "print(t2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   nan,    nan,    nan],\n",
       "        [   nan, 2.2361,    nan],\n",
       "        [2.2361,    nan,    nan]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.rand(3,3)\n",
    "t1 = torch.floor(t1*10)\n",
    "\n",
    "t2 = torch.rand(3,3)\n",
    "t2 = torch.floor(t2*10)\n",
    "t = torch.sqrt(t1-t2)\n",
    "t  # nan is because of -ve numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.5000, grad_fn=<MeanBackward0>)\n",
      "tensor([0., 0., 0., 0.])\n",
      "tensor([0.2500, 0.2500, 0.2500, 0.2500])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4], dtype=torch.float32, requires_grad=True)\n",
    "y = torch.tensor([10,20,30,40], dtype=torch.float32, requires_grad=True)\n",
    "# print(x.shape)\n",
    "# y = x+2\n",
    "z = (y-x).mean()\n",
    "print(z)\n",
    "\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7946/3617341035.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(2*x,requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 3.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3, requires_grad=True)\n",
    "y = torch.tensor(2*x,requires_grad=True)\n",
    "\n",
    "z = 3*y\n",
    "z.backward(torch.ones_like(z))\n",
    "y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample model working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight:  tensor([-1.6069, -0.5363, -0.3856,  1.4479,  0.8781], requires_grad=True)\n",
      "tensor([3., 3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9., 9.])\n",
      "tensor([12., 12., 12., 12., 12.])\n",
      "tensor([15., 15., 15., 15., 15.])\n",
      "tensor([18., 18., 18., 18., 18.])\n",
      "tensor([21., 21., 21., 21., 21.])\n",
      "tensor([24., 24., 24., 24., 24.])\n",
      "tensor([27., 27., 27., 27., 27.])\n",
      "tensor([30., 30., 30., 30., 30.])\n"
     ]
    }
   ],
   "source": [
    "weight = torch.randn(5, requires_grad=True)\n",
    "print('Weight: ',weight)\n",
    "\n",
    "def model(input):\n",
    "    output = 3*input    \n",
    "    return output\n",
    "\n",
    "for epoch in range(10):\n",
    "    model_output = model(weight)\n",
    "    model_output.backward(torch.ones_like(model_output))    \n",
    "    print(weight.grad)\n",
    "    # weight.grad.zero_()  # if you want to empty the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward and Backward propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.)\n",
    "w = torch.tensor(1.,requires_grad=True)\n",
    "y = torch.tensor(2.)\n",
    "def model(x,w):\n",
    "    return x*w\n",
    "\n",
    "# forward pass\n",
    "y_hat = model(x,w)\n",
    "L = (y_hat - y)**2\n",
    "print(L)  \n",
    "\n",
    "# backward pass\n",
    "L.backward()\n",
    "print(w.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6695315e432dad9365e64f39285f0493c8af918d3cb74b9bae4e100548ae2c82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
